{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f232a277",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "f232a277",
        "outputId": "74db9489-1c8a-4f7d-ced9-e1667f79f625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   OrderID            2000 non-null   object\n",
            " 1   Expiry_Days_Left   2000 non-null   int64 \n",
            " 2   Order_Date         2000 non-null   object\n",
            " 3   Expiry_Date        2000 non-null   object\n",
            " 4   Pallet_Size        2000 non-null   int64 \n",
            " 5   Route_Type         2000 non-null   object\n",
            " 6   Mode_of_Transport  2000 non-null   object\n",
            " 7   Urgent_Order_Flag  2000 non-null   object\n",
            " 8   Fragility          2000 non-null   object\n",
            " 9   Dispatch_Window    2000 non-null   object\n",
            " 10  Temp_Sensitive     2000 non-null   object\n",
            "dtypes: int64(2), object(9)\n",
            "memory usage: 172.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# Loading Dataset\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"../DataSets/Transport_AssignmentsRAW.csv\")\n",
        "# Transport_AssignmentsRAW\n",
        "# df.head(5)\n",
        "# print(df.head(2))\n",
        "# DIsssSdata\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0c670906",
      "metadata": {
        "id": "0c670906"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "time data \"2026-02-08\" doesn't match format \"%d/%m/%Y\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Convert string columns to datetime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mExpiry_Date\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mExpiry_Date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mm/\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mY\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mOrder_Date\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mOrder_Date\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm/\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Calculate expiry range\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1112\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1110\u001b[39m         result = arg.map(cache_array)\n\u001b[32m   1111\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1112\u001b[39m         values = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1113\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:488\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m result, tz_parsed = objects_to_datetime64ns(\n\u001b[32m    491\u001b[39m     arg,\n\u001b[32m    492\u001b[39m     dayfirst=dayfirst,\n\u001b[32m   (...)\u001b[39m\u001b[32m    496\u001b[39m     allow_object=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    497\u001b[39m )\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    500\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    501\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:519\u001b[39m, in \u001b[36m_array_strptime_with_fallback\u001b[39m\u001b[34m(arg, name, utc, fmt, exact, errors)\u001b[39m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_array_strptime_with_fallback\u001b[39m(\n\u001b[32m    509\u001b[39m     arg,\n\u001b[32m    510\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    515\u001b[39m ) -> Index:\n\u001b[32m    516\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    517\u001b[39m \u001b[33;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[32m    518\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     result, timezones = \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[32m    521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mstrptime.pyx:534\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mstrptime.pyx:355\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m: time data \"2026-02-08\" doesn't match format \"%d/%m/%Y\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
          ]
        }
      ],
      "source": [
        "# Convert string columns to datetime\n",
        "df['Expiry_Date'] = pd.to_datetime(df['Expiry_Date'], format='%d/%m/%Y')\n",
        "df['Order_Date'] = pd.to_datetime(df['Order_Date'], format='%d/%m/%Y')\n",
        "\n",
        "# Calculate expiry range\n",
        "df['Expiry_Days_Left'] = (df['Expiry_Date'] - df['Order_Date']).dt.days\n",
        "\n",
        "# Display\n",
        "print(df[['OrderID', 'Order_Date', 'Expiry_Date', 'Expiry_Days_Left']].head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "fc36e3bb",
      "metadata": {
        "id": "fc36e3bb"
      },
      "outputs": [],
      "source": [
        "# Reorder columns (make Expiry_Days_Left 2nd)\n",
        "cols = df.columns.tolist()\n",
        "cols.insert(1, cols.pop(cols.index('Expiry_Days_Left')))\n",
        "df = df[cols]\n",
        "\n",
        "# Save back to CSV\n",
        "df.to_csv(\"../DataSets/Transport_AssignmentsMOD.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "0ee3c38b",
      "metadata": {
        "id": "0ee3c38b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   OrderID            2000 non-null   object\n",
            " 1   Expiry_Days_Left   2000 non-null   int64 \n",
            " 2   Order_Date         2000 non-null   object\n",
            " 3   Expiry_Date        2000 non-null   object\n",
            " 4   Pallet_Size        2000 non-null   int64 \n",
            " 5   Route_Type         2000 non-null   object\n",
            " 6   Mode_of_Transport  2000 non-null   object\n",
            " 7   Urgent_Order_Flag  2000 non-null   object\n",
            " 8   Fragility          2000 non-null   object\n",
            " 9   Dispatch_Window    2000 non-null   object\n",
            " 10  Temp_Sensitive     2000 non-null   object\n",
            "dtypes: int64(2), object(9)\n",
            "memory usage: 172.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.describe()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2736d96f",
      "metadata": {
        "id": "2736d96f"
      },
      "outputs": [],
      "source": [
        "#Loading Required Liaberies ( WORKING WITH RANDOM FOREST KNN HANDELED BY SCIKIT LEARN )\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib  # For saving model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "89d35da1",
      "metadata": {
        "id": "89d35da1"
      },
      "outputs": [],
      "source": [
        "#Loading DataSheet\n",
        "df = pd.read_csv(\"../DataSets/Transport_AssignmentsMOD.csv\")\n",
        "# df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "33ee74e1",
      "metadata": {
        "id": "33ee74e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_5292\\771286952.py:6: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  df['Dispatch_Window'] = pd.to_datetime(df['Dispatch_Window'])\n"
          ]
        }
      ],
      "source": [
        "# df['Expiry_Date'] = pd.to_datetime(df['Expiry_Date'], format='%Y-%m-%d')\n",
        "# df['Dispatch_Window'] = pd.to_datetime(df['Dispatch_Window'], format='%Y-%m-%d')\n",
        "# df['Order_Date'] = pd.to_datetime(df['Order_Date'], format='%Y-%m-%d')\n",
        "\n",
        "# Convert Dispatch_Window and Order_Date to delivery_window_days\n",
        "df['Dispatch_Window'] = pd.to_datetime(df['Dispatch_Window'])\n",
        "df['Order_Date'] = pd.to_datetime(df['Order_Date'])\n",
        "df['Delivery_Window_Days'] = (df['Dispatch_Window'] - df['Order_Date']).dt.days\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a1f4bc51",
      "metadata": {
        "id": "a1f4bc51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "High Priority Orders: 678\n",
            "Medium Priority Orders: 202\n",
            "Low Priority Orders: 1120\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def assign_priority_fuzzy_sigmoid_robust(row,\n",
        "                                         expiry_threshold=120,          # 2 months\n",
        "                                         delivery_threshold=10,         # 10 days\n",
        "                                         high_cutoff=0.6,\n",
        "                                         medium_cutoff=0.4,\n",
        "                                         weights=None,\n",
        "                                         k=0.08):                       # Sharper sigmoid\n",
        "    \"\"\"\n",
        "    Robust industrial fuzzy logic for assigning priority labels to dispatch items.\n",
        "    Combines rule-based overrides and smooth sigmoid-based scoring.\n",
        "\n",
        "    Parameters:\n",
        "        expiry_threshold (int): Days threshold where expiry becomes critical\n",
        "        delivery_threshold (int): Days threshold for delivery urgency\n",
        "        high_cutoff (float): Score threshold for High priority\n",
        "        medium_cutoff (float): Score threshold for Medium priority\n",
        "        weights (dict): Weight mapping for all five parameters\n",
        "        k (float): Sigmoid steepness factor (higher = sharper cutoff)\n",
        "\n",
        "    Returns:\n",
        "        str: 'High', 'Medium', or 'Low'\n",
        "    \"\"\"\n",
        "    if weights is None:\n",
        "        weights = {\n",
        "            'expiry': 0.4,\n",
        "            'delivery': 0.3,\n",
        "            'urgent': 0.2,\n",
        "            'temp': 0.05,\n",
        "            'fragile': 0.05\n",
        "        }\n",
        "\n",
        "    expiry_days = row['Expiry_Days_Left']\n",
        "    delivery_days = row['Delivery_Window_Days']\n",
        "\n",
        "    # ðŸ§  Sigmoid fuzzy scores (scaled to smooth transitions)\n",
        "    expiry_score = 1 / (1 + np.exp(k * (expiry_days - expiry_threshold)))\n",
        "    delivery_score = 1 / (1 + np.exp(k * (delivery_days - delivery_threshold)))\n",
        "\n",
        "    urgent_score = 1 if row['Urgent_Order_Flag'] == 'Yes' else 0\n",
        "    temp_score = 1 if row['Temp_Sensitive'] == 'Yes' else 0\n",
        "    fragile_score = 1 if row['Fragility'] == 'Yes' else 0\n",
        "\n",
        "    # ðŸ”’ Hard Rule Overrides (Business-critical triggers)\n",
        "    # Rule 1: Expiry very soon AND urgent\n",
        "    if expiry_days <= 30 and row['Urgent_Order_Flag'] == 'Yes':\n",
        "        return 'High'\n",
        "\n",
        "    # Rule 2: Temp-sensitive AND near expiry\n",
        "    if expiry_days <= 30 and row['Temp_Sensitive'] == 'Yes':\n",
        "        return 'High'\n",
        "\n",
        "    # Rule 3: Tight delivery window AND urgent\n",
        "    if delivery_days <= 5 and row['Urgent_Order_Flag'] == 'Yes':\n",
        "        return 'High'\n",
        "\n",
        "    # Rule 4: Expiry + Delivery both extremely tight\n",
        "    if expiry_days <= 10 and delivery_days <= 5:\n",
        "        return 'High'\n",
        "\n",
        "    # Rule 5: Fragile and urgent (special handling needed)\n",
        "    if row['Urgent_Order_Flag'] == 'Yes' and row['Fragility'] == 'Yes':\n",
        "        return 'High'\n",
        "\n",
        "    # Rule 6: Very relaxed, non-urgent case\n",
        "    if expiry_days > 600 and delivery_days > 45 and row['Urgent_Order_Flag'] == 'No':\n",
        "        return 'Low'\n",
        "\n",
        "    # ðŸŽ¯ Weighted fuzzy scoring\n",
        "    total_score = (\n",
        "        expiry_score * weights['expiry'] +\n",
        "        delivery_score * weights['delivery'] +\n",
        "        urgent_score * weights['urgent'] +\n",
        "        temp_score * weights['temp'] +\n",
        "        fragile_score * weights['fragile']\n",
        "    )\n",
        "\n",
        "    # ðŸ”½ Priority Classification\n",
        "    if total_score >= high_cutoff:\n",
        "        return 'High'\n",
        "    elif total_score >= medium_cutoff:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'\n",
        "\n",
        "\n",
        "\n",
        "df['Priority_Label'] = df.apply(assign_priority_fuzzy_sigmoid_robust, axis=1)\n",
        "\n",
        "# Split data\n",
        "high_df = df[df['Priority_Label'] == 'High']\n",
        "medium_df = df[df['Priority_Label'] == 'Medium']\n",
        "low_df = df[df['Priority_Label'] == 'Low']\n",
        "\n",
        "print(f\"High Priority Orders: {len(high_df)}\")\n",
        "print(f\"Medium Priority Orders: {len(medium_df)}\")\n",
        "print(f\"Low Priority Orders: {len(low_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "84c1a211",
      "metadata": {
        "id": "84c1a211"
      },
      "outputs": [],
      "source": [
        "#dataset for ml\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 1: Feature Selection\n",
        "features = [\n",
        "    'Pallet_Size',\n",
        "    'Route_Type',\n",
        "    'Mode_of_Transport',\n",
        "    'Urgent_Order_Flag',\n",
        "    'Fragility',\n",
        "    'Temp_Sensitive',\n",
        "    'Expiry_Days_Left',\n",
        "    'Dispatch_Window',  # will convert this to days\n",
        "    'Order_Date'\n",
        "]\n",
        "\n",
        "# Convert Dispatch_Window and Order_Date to delivery_window_days\n",
        "df['Dispatch_Window'] = pd.to_datetime(df['Dispatch_Window'])\n",
        "df['Order_Date'] = pd.to_datetime(df['Order_Date'])\n",
        "df['Delivery_Window_Days'] = (df['Dispatch_Window'] - df['Order_Date']).dt.days\n",
        "\n",
        "# Keep only required features + label\n",
        "ml_df = df[[\n",
        "    'Pallet_Size', 'Route_Type', 'Mode_of_Transport', 'Urgent_Order_Flag',\n",
        "    'Fragility', 'Temp_Sensitive', 'Expiry_Days_Left', 'Delivery_Window_Days', \n",
        "    'Priority_Label'\n",
        "]]\n",
        "\n",
        "# Encode categorical columns\n",
        "label_encoders = {}\n",
        "for col in ['Route_Type', 'Mode_of_Transport', 'Urgent_Order_Flag', 'Fragility', 'Temp_Sensitive']:\n",
        "    le = LabelEncoder()\n",
        "    ml_df.loc[:, col] = le.fit_transform(ml_df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Encode output label\n",
        "le_priority = LabelEncoder()\n",
        "# ml_df.loc[:, 'Priority_Label'] = le_priority.fit_transform(ml_df['Priority_Label'])\n",
        "ml_df.loc[:, 'Priority_Label'] = le_priority.fit_transform(ml_df['Priority_Label'])\n",
        "# ml_df['Priority_Label'] = le_priority.fit_transform(ml_df['Priority_Label'].astype(str))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "1a308fe7",
      "metadata": {
        "id": "1a308fe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 2 1]\n",
            "int64\n"
          ]
        }
      ],
      "source": [
        "#BRUT FORCE\n",
        "\n",
        "# Manually map string labels to integers\n",
        "priority_mapping = {\n",
        "    'Low': 0,\n",
        "    'Medium': 1,\n",
        "    'High': 2\n",
        "}\n",
        "\n",
        "# Apply the mapping manually\n",
        "df['Encoded_Priority_Label'] = df['Priority_Label'].map(priority_mapping)\n",
        "\n",
        "# Check results\n",
        "print(df['Encoded_Priority_Label'].unique())\n",
        "print(df['Encoded_Priority_Label'].dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "51417111",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_5292\\2616058964.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ml_df['Encoded_Priority_Label'] = df['Encoded_Priority_Label']\n"
          ]
        }
      ],
      "source": [
        "# Ensure encoded label is added to ml_df from df\n",
        "ml_df['Encoded_Priority_Label'] = df['Encoded_Priority_Label']\n",
        "\n",
        "# Define features (X) and label (y)\n",
        "X = ml_df.drop(['Priority_Label', 'Encoded_Priority_Label'], axis=1)\n",
        "y = ml_df['Encoded_Priority_Label']\n",
        "\n",
        "# Split into train/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "fb14b3b7",
      "metadata": {
        "id": "fb14b3b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            " [[223   1   0]\n",
            " [  3  37   0]\n",
            " [  0   0 136]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        High       0.99      1.00      0.99       224\n",
            "         Low       0.97      0.93      0.95        40\n",
            "      Medium       1.00      1.00      1.00       136\n",
            "\n",
            "    accuracy                           0.99       400\n",
            "   macro avg       0.99      0.97      0.98       400\n",
            "weighted avg       0.99      0.99      0.99       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=le_priority.classes_))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "77fb3dd2",
      "metadata": {
        "id": "77fb3dd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Priority_Label\n",
            "Low       1120\n",
            "High       678\n",
            "Medium     202\n",
            "Name: count, dtype: int64\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(df['Priority_Label'].value_counts())\n",
        "\n",
        "print(df['Priority_Label'].isnull().sum())\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "3a83e746",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "High Priority Orders: 678\n",
            "Medium Priority Orders: 202\n",
            "Low Priority Orders: 1120\n"
          ]
        }
      ],
      "source": [
        "#SEPERATE DATAFRAMES FOR PRIORITY\n",
        "\n",
        "high_df = df[df['Priority_Label'] == 'High']\n",
        "medium_df = df[df['Priority_Label'] == 'Medium']\n",
        "low_df = df[df['Priority_Label'] == 'Low']\n",
        "\n",
        " \n",
        "print(f\"High Priority Orders: {len(high_df)}\")\n",
        "print(f\"Medium Priority Orders: {len(medium_df)}\")\n",
        "print(f\"Low Priority Orders: {len(low_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a3816788",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['..\\\\TrainedModel\\\\priority_label_encoder.pkl']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save model\n",
        "joblib.dump(model, '..\\\\TrainedModel\\\\dispatch_priority_model.pkl')\n",
        "\n",
        "# # Also save encoders if needed later\n",
        "joblib.dump(label_encoders, '..\\\\TrainedModel\\\\label_encoders.pkl')\n",
        "joblib.dump(le_priority, '..\\\\TrainedModel\\\\priority_label_encoder.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "aa7dd6bf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Test Data Format ::: Route_Type classes: ['Intercity' 'Interstate' 'Local']\n",
            " Test Data Format ::: Mode_of_Transport classes: ['Big Truck' 'Medium Truck' 'Small Truck']\n",
            " Test Data Format ::: Urgent_Order_Flag classes: ['No' 'Yes']\n",
            " Test Data Format ::: Fragility classes: ['No' 'Yes']\n",
            " Test Data Format ::: Temp_Sensitive classes: ['No' 'Yes']\n"
          ]
        }
      ],
      "source": [
        "# 3 MODEL USING AND HYPER PARAMETERS \n",
        "\n",
        "for col, le in label_encoders.items():\n",
        "    print(f\" Test Data Format ::: {col} classes: {le.classes_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9acc0466",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Pallet_Size  Expiry_Days_Left  Delivery_Window_Days Predicted_Priority\n",
            "0          100                 5                    10             Medium\n",
            "1           80                90                    25                Low\n",
            "2          120               360                    60               High\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load model and encoders\n",
        "model = joblib.load('..\\\\TrainedModel\\\\dispatch_priority_model.pkl')\n",
        "label_encoders = joblib.load('..\\\\TrainedModel\\\\label_encoders.pkl')\n",
        "le_priority = joblib.load('..\\\\TrainedModel\\\\priority_label_encoder.pkl')\n",
        "\n",
        "# Test data with possible new/unseen values\n",
        "new_data = pd.DataFrame([\n",
        "    {\n",
        "        'Pallet_Size': 100,\n",
        "        'Route_Type': 'Intercity',        # OK\n",
        "        'Mode_of_Transport': 'Medium Truck',  # OK\n",
        "        'Urgent_Order_Flag': 'Yes',\n",
        "        'Fragility': 'Yes',\n",
        "        'Temp_Sensitive': 'Yes',\n",
        "        'Expiry_Days_Left': 5,\n",
        "        'Delivery_Window_Days': 10\n",
        "    },\n",
        "    {\n",
        "        'Pallet_Size': 80,\n",
        "        'Route_Type': 'Intracity',\n",
        "        'Mode_of_Transport': 'Mini Truck',\n",
        "        'Urgent_Order_Flag': 'No',\n",
        "        'Fragility': 'Yes',\n",
        "        'Temp_Sensitive': 'No',\n",
        "        'Expiry_Days_Left': 90,\n",
        "        'Delivery_Window_Days': 25\n",
        "    },\n",
        "    {\n",
        "        'Pallet_Size': 120,\n",
        "        'Route_Type': 'Interstate',\n",
        "        'Mode_of_Transport': 'Big Truck',\n",
        "        'Urgent_Order_Flag': 'No',\n",
        "        'Fragility': 'No',\n",
        "        'Temp_Sensitive': 'No',\n",
        "        'Expiry_Days_Left': 360,\n",
        "        'Delivery_Window_Days': 60\n",
        "    }\n",
        "])\n",
        "\n",
        "# Encode new data safely by replacing unseen labels\n",
        "for col in ['Route_Type', 'Mode_of_Transport', 'Urgent_Order_Flag', 'Fragility', 'Temp_Sensitive']:\n",
        "    le = label_encoders[col]\n",
        "    \n",
        "    # Ensure all values are known to encoder\n",
        "    new_data[col] = new_data[col].apply(lambda x: x if x in le.classes_ else le.classes_[0])\n",
        "    \n",
        "    # Re-transform with safe values\n",
        "    new_data[col] = le.transform(new_data[col])\n",
        "\n",
        "# Predict\n",
        "prediction_encoded = model.predict(new_data)\n",
        "prediction_label = le_priority.inverse_transform(prediction_encoded)\n",
        "\n",
        "# Results\n",
        "new_data['Predicted_Priority'] = prediction_label\n",
        "print(new_data[['Pallet_Size', 'Expiry_Days_Left', 'Delivery_Window_Days', 'Predicted_Priority']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "c7e132a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming 'df' contains the final dataframe after priority assignment\n",
        "csv_path = \"../DataSets/Transport_AssignmentsMLGEN.csv\"\n",
        "df.to_csv(csv_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
